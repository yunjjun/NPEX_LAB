{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Finetune.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f47a72101d294ab2b07c2a3ea643012c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3a9d10a452e9408d8f9c6887d35e9e26","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dfd140c5697d46338e08357f861e3ad0","IPY_MODEL_2a45e369fed84a53b3c15319786e1164"]}},"3a9d10a452e9408d8f9c6887d35e9e26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfd140c5697d46338e08357f861e3ad0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_169498b73be7416a90207950d686df05","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8eadbde04b5e4f089ad5f7ffb1e1ef5e"}},"2a45e369fed84a53b3c15319786e1164":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_25308df15cc24004aa2944738e89af23","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170500096/? [00:21&lt;00:00, 54834642.07it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_59511856ff114ecab0a453158af687fc"}},"169498b73be7416a90207950d686df05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8eadbde04b5e4f089ad5f7ffb1e1ef5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"25308df15cc24004aa2944738e89af23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"59511856ff114ecab0a453158af687fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"OdUzwkisrc76","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f47a72101d294ab2b07c2a3ea643012c","3a9d10a452e9408d8f9c6887d35e9e26","dfd140c5697d46338e08357f861e3ad0","2a45e369fed84a53b3c15319786e1164","169498b73be7416a90207950d686df05","8eadbde04b5e4f089ad5f7ffb1e1ef5e","25308df15cc24004aa2944738e89af23","59511856ff114ecab0a453158af687fc"]},"executionInfo":{"status":"ok","timestamp":1597111643459,"user_tz":-540,"elapsed":335803,"user":{"displayName":"이남우","photoUrl":"","userId":"10211005963762835510"}},"outputId":"9dbc262e-da41-4542-8fc1-0cfa0fea961a"},"source":["'''Train CIFAR10 with PyTorch.'''\n","import torch\n","import torch.optim as optim\n","import torch.optim.lr_scheduler as lr_scheduler\n","import torch.backends.cudnn as cudnn\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","drive_path = \"drive/My Drive/NPEX_2020_Quantization\" # do not modify this line\n","relative_path = \"/practice\"   # set to your relative path \n","\n","base_path = drive_path + relative_path\n","\n","import sys\n","sys.path.append(base_path)\n","\n","from train_test import train, test\n","\n","LR = 0.01\n","EPOCH = 5\n","\n","# Data\n","print('==> Preparing data')\n","from dataset import cifar10_dataset\n","trainloader, testloader = cifar10_dataset(base_path + \"/data\")\n","\n","# Model\n","print('==> Building model')\n","from resnet_quant import ResNet18\n","model = ResNet18()\n","model.load_state_dict(torch.load(base_path + \"/train_best.pth\"))\n","\n","if torch.cuda.is_available():\n","    model.cuda()\n","    model = torch.nn.DataParallel(model)\n","    cudnn.benchmark = True\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","print('==> Full-precision model accuracy')\n","from quant_op import Q_ReLU, Q_Conv2d, Q_Linear\n","test(model, testloader, criterion)\n","\n","for name, module in model.named_modules():\n","    if isinstance(module, Q_ReLU):\n","        module.n_lv = 8\n","        module.bound = 1\n","    \n","    if isinstance(module, (Q_Conv2d, Q_Linear)):\n","        module.n_lv = 8\n","        module.ratio = 0.5\n","\n","print('==> Quantized model accuracy')\n","from quant_op import Q_ReLU, Q_Conv2d, Q_Linear\n","test(model, testloader, criterion)\n","\n","best_acc = 0  # best test accuracy\n","start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n","\n","optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n","scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCH, last_epoch=start_epoch-1)\n","\n","for epoch in range(start_epoch, start_epoch + EPOCH):\n","    scheduler.step()\n","    train(model, trainloader, criterion, optimizer, epoch)\n","    acc = test(model, testloader, criterion)\n","\n","    if acc > best_acc:\n","        best_acc = acc\n","        torch.save(model.module.state_dict(), base_path +  \"quant_best.pth\")\n","\n","print('==> Fine-tuned model accuracy')\n","from quant_op import Q_ReLU, Q_Conv2d, Q_Linear\n","test(model, testloader, criterion)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","==> Preparing data\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to drive/My Drive/NPEX_2020_Quantization/practice/data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f47a72101d294ab2b07c2a3ea643012c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting drive/My Drive/NPEX_2020_Quantization/practice/data/cifar-10-python.tar.gz to drive/My Drive/NPEX_2020_Quantization/practice/data\n","Files already downloaded and verified\n","==> Building model\n","==> Full-precision model accuracy\n","Test: [10/100]\tTime 0.028 (0.118)\tLoss 0.1693 (0.2120)\tPrec@1 95.000 (94.300)\n","Test: [20/100]\tTime 0.027 (0.073)\tLoss 0.3840 (0.2106)\tPrec@1 93.000 (94.650)\n","Test: [30/100]\tTime 0.032 (0.059)\tLoss 0.1171 (0.2190)\tPrec@1 96.000 (94.667)\n","Test: [40/100]\tTime 0.031 (0.052)\tLoss 0.1930 (0.2174)\tPrec@1 97.000 (94.750)\n","Test: [50/100]\tTime 0.029 (0.048)\tLoss 0.3337 (0.2224)\tPrec@1 94.000 (94.660)\n","Test: [60/100]\tTime 0.027 (0.045)\tLoss 0.1739 (0.2162)\tPrec@1 96.000 (94.817)\n","Test: [70/100]\tTime 0.027 (0.043)\tLoss 0.1721 (0.2082)\tPrec@1 96.000 (95.014)\n","Test: [80/100]\tTime 0.026 (0.042)\tLoss 0.0803 (0.2097)\tPrec@1 96.000 (95.013)\n","Test: [90/100]\tTime 0.026 (0.040)\tLoss 0.2229 (0.2079)\tPrec@1 94.000 (94.989)\n","Test: [100/100]\tTime 0.026 (0.039)\tLoss 0.0745 (0.2060)\tPrec@1 97.000 (94.980)\n"," * Prec@1 94.980\n","==> Quantized model accuracy\n","Test: [10/100]\tTime 0.043 (0.101)\tLoss 0.6349 (0.6542)\tPrec@1 89.000 (84.400)\n","Test: [20/100]\tTime 0.044 (0.073)\tLoss 0.7419 (0.6521)\tPrec@1 82.000 (84.550)\n","Test: [30/100]\tTime 0.044 (0.064)\tLoss 0.7725 (0.6547)\tPrec@1 86.000 (84.867)\n","Test: [40/100]\tTime 0.044 (0.059)\tLoss 0.7525 (0.6527)\tPrec@1 84.000 (84.750)\n","Test: [50/100]\tTime 0.044 (0.056)\tLoss 0.9399 (0.6533)\tPrec@1 76.000 (84.500)\n","Test: [60/100]\tTime 0.056 (0.054)\tLoss 0.8306 (0.6562)\tPrec@1 85.000 (84.733)\n","Test: [70/100]\tTime 0.044 (0.053)\tLoss 0.6954 (0.6531)\tPrec@1 81.000 (84.714)\n","Test: [80/100]\tTime 0.044 (0.052)\tLoss 0.5551 (0.6545)\tPrec@1 83.000 (84.625)\n","Test: [90/100]\tTime 0.042 (0.051)\tLoss 0.5673 (0.6542)\tPrec@1 84.000 (84.533)\n","Test: [100/100]\tTime 0.045 (0.050)\tLoss 0.4928 (0.6517)\tPrec@1 87.000 (84.480)\n"," * Prec@1 84.480\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 0: [10/196]\tTime 0.217 (0.411)\tData 0.007 (0.062)\tLoss 0.0656 (0.0522)\tPrec@1 98.047 (98.516)\n","Epoch 0: [20/196]\tTime 0.216 (0.315)\tData 0.002 (0.031)\tLoss 0.0180 (0.0502)\tPrec@1 100.000 (98.496)\n","Epoch 0: [30/196]\tTime 0.219 (0.283)\tData 0.002 (0.021)\tLoss 0.0629 (0.0463)\tPrec@1 97.656 (98.607)\n","Epoch 0: [40/196]\tTime 0.219 (0.267)\tData 0.002 (0.016)\tLoss 0.0423 (0.0451)\tPrec@1 98.828 (98.604)\n","Epoch 0: [50/196]\tTime 0.220 (0.258)\tData 0.002 (0.013)\tLoss 0.0764 (0.0463)\tPrec@1 97.266 (98.508)\n","Epoch 0: [60/196]\tTime 0.221 (0.251)\tData 0.002 (0.012)\tLoss 0.0424 (0.0461)\tPrec@1 99.219 (98.516)\n","Epoch 0: [70/196]\tTime 0.225 (0.247)\tData 0.001 (0.010)\tLoss 0.0601 (0.0481)\tPrec@1 98.047 (98.454)\n","Epoch 0: [80/196]\tTime 0.222 (0.244)\tData 0.002 (0.009)\tLoss 0.0449 (0.0477)\tPrec@1 98.438 (98.481)\n","Epoch 0: [90/196]\tTime 0.220 (0.241)\tData 0.002 (0.008)\tLoss 0.0526 (0.0489)\tPrec@1 98.438 (98.424)\n","Epoch 0: [100/196]\tTime 0.222 (0.240)\tData 0.001 (0.008)\tLoss 0.0406 (0.0488)\tPrec@1 99.219 (98.422)\n","Epoch 0: [110/196]\tTime 0.222 (0.238)\tData 0.001 (0.007)\tLoss 0.0234 (0.0487)\tPrec@1 99.609 (98.430)\n","Epoch 0: [120/196]\tTime 0.224 (0.237)\tData 0.001 (0.007)\tLoss 0.0494 (0.0495)\tPrec@1 98.828 (98.421)\n","Epoch 0: [130/196]\tTime 0.218 (0.236)\tData 0.002 (0.006)\tLoss 0.0503 (0.0491)\tPrec@1 98.438 (98.438)\n","Epoch 0: [140/196]\tTime 0.225 (0.235)\tData 0.002 (0.006)\tLoss 0.0457 (0.0496)\tPrec@1 98.047 (98.415)\n","Epoch 0: [150/196]\tTime 0.225 (0.234)\tData 0.002 (0.006)\tLoss 0.0565 (0.0500)\tPrec@1 98.047 (98.406)\n","Epoch 0: [160/196]\tTime 0.225 (0.234)\tData 0.002 (0.005)\tLoss 0.0235 (0.0495)\tPrec@1 98.828 (98.413)\n","Epoch 0: [170/196]\tTime 0.225 (0.233)\tData 0.002 (0.005)\tLoss 0.0270 (0.0497)\tPrec@1 99.609 (98.417)\n","Epoch 0: [180/196]\tTime 0.226 (0.233)\tData 0.003 (0.005)\tLoss 0.0174 (0.0495)\tPrec@1 99.219 (98.422)\n","Epoch 0: [190/196]\tTime 0.227 (0.232)\tData 0.002 (0.005)\tLoss 0.0528 (0.0494)\tPrec@1 98.438 (98.421)\n","Test: [10/100]\tTime 0.044 (0.100)\tLoss 0.2879 (0.2728)\tPrec@1 91.000 (92.000)\n","Test: [20/100]\tTime 0.044 (0.073)\tLoss 0.4110 (0.2726)\tPrec@1 89.000 (91.950)\n","Test: [30/100]\tTime 0.044 (0.064)\tLoss 0.2438 (0.2872)\tPrec@1 94.000 (91.767)\n","Test: [40/100]\tTime 0.045 (0.059)\tLoss 0.2750 (0.2903)\tPrec@1 93.000 (91.775)\n","Test: [50/100]\tTime 0.045 (0.057)\tLoss 0.4010 (0.2970)\tPrec@1 90.000 (91.560)\n","Test: [60/100]\tTime 0.045 (0.055)\tLoss 0.3436 (0.2940)\tPrec@1 93.000 (91.733)\n","Test: [70/100]\tTime 0.050 (0.053)\tLoss 0.2329 (0.2816)\tPrec@1 92.000 (92.029)\n","Test: [80/100]\tTime 0.044 (0.052)\tLoss 0.2927 (0.2873)\tPrec@1 92.000 (92.037)\n","Test: [90/100]\tTime 0.043 (0.051)\tLoss 0.4414 (0.2850)\tPrec@1 91.000 (92.089)\n","Test: [100/100]\tTime 0.043 (0.050)\tLoss 0.2002 (0.2817)\tPrec@1 91.000 (92.220)\n"," * Prec@1 92.220\n","Epoch 1: [10/196]\tTime 0.228 (0.323)\tData 0.002 (0.076)\tLoss 0.0348 (0.0431)\tPrec@1 99.219 (98.594)\n","Epoch 1: [20/196]\tTime 0.228 (0.276)\tData 0.002 (0.039)\tLoss 0.0393 (0.0371)\tPrec@1 99.219 (98.770)\n","Epoch 1: [30/196]\tTime 0.229 (0.260)\tData 0.001 (0.026)\tLoss 0.0295 (0.0377)\tPrec@1 98.438 (98.750)\n","Epoch 1: [40/196]\tTime 0.231 (0.253)\tData 0.002 (0.020)\tLoss 0.0280 (0.0352)\tPrec@1 98.438 (98.828)\n","Epoch 1: [50/196]\tTime 0.229 (0.248)\tData 0.002 (0.017)\tLoss 0.0252 (0.0343)\tPrec@1 99.219 (98.867)\n","Epoch 1: [60/196]\tTime 0.230 (0.245)\tData 0.002 (0.014)\tLoss 0.0365 (0.0340)\tPrec@1 98.828 (98.893)\n","Epoch 1: [70/196]\tTime 0.229 (0.243)\tData 0.001 (0.012)\tLoss 0.0165 (0.0331)\tPrec@1 99.609 (98.962)\n","Epoch 1: [80/196]\tTime 0.229 (0.241)\tData 0.001 (0.011)\tLoss 0.0306 (0.0321)\tPrec@1 98.828 (99.009)\n","Epoch 1: [90/196]\tTime 0.230 (0.240)\tData 0.002 (0.010)\tLoss 0.0344 (0.0317)\tPrec@1 98.047 (99.002)\n","Epoch 1: [100/196]\tTime 0.230 (0.239)\tData 0.002 (0.009)\tLoss 0.0140 (0.0315)\tPrec@1 100.000 (99.004)\n","Epoch 1: [110/196]\tTime 0.228 (0.238)\tData 0.001 (0.008)\tLoss 0.0190 (0.0316)\tPrec@1 99.219 (99.013)\n","Epoch 1: [120/196]\tTime 0.228 (0.237)\tData 0.002 (0.008)\tLoss 0.0353 (0.0309)\tPrec@1 99.219 (99.043)\n","Epoch 1: [130/196]\tTime 0.231 (0.237)\tData 0.002 (0.007)\tLoss 0.0330 (0.0312)\tPrec@1 99.219 (99.026)\n","Epoch 1: [140/196]\tTime 0.226 (0.236)\tData 0.002 (0.007)\tLoss 0.0283 (0.0311)\tPrec@1 99.219 (99.029)\n","Epoch 1: [150/196]\tTime 0.228 (0.236)\tData 0.002 (0.007)\tLoss 0.0241 (0.0307)\tPrec@1 99.609 (99.057)\n","Epoch 1: [160/196]\tTime 0.229 (0.235)\tData 0.002 (0.006)\tLoss 0.0146 (0.0307)\tPrec@1 99.609 (99.058)\n","Epoch 1: [170/196]\tTime 0.228 (0.235)\tData 0.001 (0.006)\tLoss 0.0410 (0.0307)\tPrec@1 98.438 (99.072)\n","Epoch 1: [180/196]\tTime 0.226 (0.234)\tData 0.002 (0.006)\tLoss 0.0404 (0.0310)\tPrec@1 99.219 (99.062)\n","Epoch 1: [190/196]\tTime 0.229 (0.234)\tData 0.001 (0.006)\tLoss 0.0087 (0.0307)\tPrec@1 100.000 (99.069)\n","Test: [10/100]\tTime 0.047 (0.101)\tLoss 0.2800 (0.2616)\tPrec@1 92.000 (92.300)\n","Test: [20/100]\tTime 0.045 (0.073)\tLoss 0.3750 (0.2778)\tPrec@1 90.000 (92.150)\n","Test: [30/100]\tTime 0.045 (0.064)\tLoss 0.1440 (0.2792)\tPrec@1 94.000 (91.900)\n","Test: [40/100]\tTime 0.044 (0.059)\tLoss 0.3286 (0.2842)\tPrec@1 92.000 (91.800)\n","Test: [50/100]\tTime 0.045 (0.056)\tLoss 0.4565 (0.2922)\tPrec@1 89.000 (91.720)\n","Test: [60/100]\tTime 0.046 (0.054)\tLoss 0.1221 (0.2875)\tPrec@1 96.000 (92.000)\n","Test: [70/100]\tTime 0.044 (0.053)\tLoss 0.2767 (0.2772)\tPrec@1 91.000 (92.243)\n","Test: [80/100]\tTime 0.044 (0.052)\tLoss 0.1981 (0.2812)\tPrec@1 94.000 (92.200)\n","Test: [90/100]\tTime 0.044 (0.051)\tLoss 0.2615 (0.2828)\tPrec@1 93.000 (92.133)\n","Test: [100/100]\tTime 0.043 (0.050)\tLoss 0.1678 (0.2793)\tPrec@1 92.000 (92.260)\n"," * Prec@1 92.260\n","Epoch 2: [10/196]\tTime 0.227 (0.332)\tData 0.000 (0.086)\tLoss 0.0091 (0.0280)\tPrec@1 100.000 (99.023)\n","Epoch 2: [20/196]\tTime 0.224 (0.279)\tData 0.002 (0.044)\tLoss 0.0183 (0.0268)\tPrec@1 100.000 (99.160)\n","Epoch 2: [30/196]\tTime 0.226 (0.262)\tData 0.002 (0.030)\tLoss 0.0079 (0.0250)\tPrec@1 100.000 (99.271)\n","Epoch 2: [40/196]\tTime 0.223 (0.253)\tData 0.002 (0.023)\tLoss 0.0362 (0.0238)\tPrec@1 98.438 (99.287)\n","Epoch 2: [50/196]\tTime 0.226 (0.248)\tData 0.001 (0.018)\tLoss 0.0194 (0.0235)\tPrec@1 99.609 (99.297)\n","Epoch 2: [60/196]\tTime 0.227 (0.244)\tData 0.002 (0.016)\tLoss 0.0351 (0.0244)\tPrec@1 98.828 (99.290)\n","Epoch 2: [70/196]\tTime 0.226 (0.242)\tData 0.002 (0.014)\tLoss 0.0115 (0.0240)\tPrec@1 99.609 (99.314)\n","Epoch 2: [80/196]\tTime 0.227 (0.240)\tData 0.002 (0.012)\tLoss 0.0108 (0.0232)\tPrec@1 99.609 (99.346)\n","Epoch 2: [90/196]\tTime 0.227 (0.238)\tData 0.001 (0.011)\tLoss 0.0167 (0.0225)\tPrec@1 99.609 (99.371)\n","Epoch 2: [100/196]\tTime 0.226 (0.237)\tData 0.001 (0.010)\tLoss 0.0114 (0.0217)\tPrec@1 99.609 (99.387)\n","Epoch 2: [110/196]\tTime 0.227 (0.236)\tData 0.001 (0.009)\tLoss 0.0164 (0.0212)\tPrec@1 99.609 (99.407)\n","Epoch 2: [120/196]\tTime 0.226 (0.235)\tData 0.002 (0.009)\tLoss 0.0149 (0.0207)\tPrec@1 99.609 (99.414)\n","Epoch 2: [130/196]\tTime 0.226 (0.235)\tData 0.002 (0.008)\tLoss 0.0275 (0.0203)\tPrec@1 99.609 (99.432)\n","Epoch 2: [140/196]\tTime 0.227 (0.234)\tData 0.001 (0.008)\tLoss 0.0169 (0.0200)\tPrec@1 99.609 (99.439)\n","Epoch 2: [150/196]\tTime 0.227 (0.234)\tData 0.002 (0.007)\tLoss 0.0361 (0.0197)\tPrec@1 98.828 (99.448)\n","Epoch 2: [160/196]\tTime 0.228 (0.233)\tData 0.001 (0.007)\tLoss 0.0169 (0.0196)\tPrec@1 100.000 (99.448)\n","Epoch 2: [170/196]\tTime 0.229 (0.233)\tData 0.001 (0.007)\tLoss 0.0160 (0.0194)\tPrec@1 99.219 (99.444)\n","Epoch 2: [180/196]\tTime 0.224 (0.233)\tData 0.002 (0.006)\tLoss 0.0207 (0.0192)\tPrec@1 98.438 (99.444)\n","Epoch 2: [190/196]\tTime 0.228 (0.232)\tData 0.001 (0.006)\tLoss 0.0098 (0.0189)\tPrec@1 100.000 (99.461)\n","Test: [10/100]\tTime 0.045 (0.100)\tLoss 0.2957 (0.2246)\tPrec@1 91.000 (93.600)\n","Test: [20/100]\tTime 0.044 (0.073)\tLoss 0.3059 (0.2363)\tPrec@1 91.000 (93.300)\n","Test: [30/100]\tTime 0.046 (0.064)\tLoss 0.1292 (0.2459)\tPrec@1 96.000 (93.333)\n","Test: [40/100]\tTime 0.045 (0.060)\tLoss 0.3394 (0.2516)\tPrec@1 94.000 (93.300)\n","Test: [50/100]\tTime 0.044 (0.057)\tLoss 0.5014 (0.2621)\tPrec@1 88.000 (93.040)\n","Test: [60/100]\tTime 0.045 (0.055)\tLoss 0.1509 (0.2561)\tPrec@1 94.000 (93.167)\n","Test: [70/100]\tTime 0.051 (0.053)\tLoss 0.2783 (0.2497)\tPrec@1 91.000 (93.271)\n","Test: [80/100]\tTime 0.044 (0.052)\tLoss 0.1528 (0.2519)\tPrec@1 94.000 (93.250)\n","Test: [90/100]\tTime 0.043 (0.051)\tLoss 0.2167 (0.2525)\tPrec@1 94.000 (93.222)\n","Test: [100/100]\tTime 0.043 (0.051)\tLoss 0.1278 (0.2474)\tPrec@1 96.000 (93.350)\n"," * Prec@1 93.350\n","Epoch 3: [10/196]\tTime 0.227 (0.332)\tData 0.005 (0.087)\tLoss 0.0122 (0.0187)\tPrec@1 100.000 (99.609)\n","Epoch 3: [20/196]\tTime 0.229 (0.280)\tData 0.002 (0.044)\tLoss 0.0109 (0.0183)\tPrec@1 99.609 (99.551)\n","Epoch 3: [30/196]\tTime 0.229 (0.263)\tData 0.002 (0.030)\tLoss 0.0093 (0.0182)\tPrec@1 99.609 (99.518)\n","Epoch 3: [40/196]\tTime 0.229 (0.254)\tData 0.002 (0.023)\tLoss 0.0102 (0.0166)\tPrec@1 100.000 (99.580)\n","Epoch 3: [50/196]\tTime 0.228 (0.249)\tData 0.001 (0.019)\tLoss 0.0141 (0.0160)\tPrec@1 99.609 (99.602)\n","Epoch 3: [60/196]\tTime 0.229 (0.245)\tData 0.002 (0.016)\tLoss 0.0135 (0.0160)\tPrec@1 99.609 (99.583)\n","Epoch 3: [70/196]\tTime 0.229 (0.243)\tData 0.002 (0.014)\tLoss 0.0231 (0.0156)\tPrec@1 99.219 (99.581)\n","Epoch 3: [80/196]\tTime 0.228 (0.241)\tData 0.002 (0.012)\tLoss 0.0059 (0.0151)\tPrec@1 100.000 (99.600)\n","Epoch 3: [90/196]\tTime 0.228 (0.240)\tData 0.001 (0.011)\tLoss 0.0031 (0.0159)\tPrec@1 100.000 (99.579)\n","Epoch 3: [100/196]\tTime 0.227 (0.238)\tData 0.002 (0.010)\tLoss 0.0164 (0.0160)\tPrec@1 99.609 (99.570)\n","Epoch 3: [110/196]\tTime 0.226 (0.237)\tData 0.004 (0.009)\tLoss 0.0142 (0.0159)\tPrec@1 99.609 (99.581)\n","Epoch 3: [120/196]\tTime 0.227 (0.237)\tData 0.002 (0.009)\tLoss 0.0047 (0.0158)\tPrec@1 100.000 (99.577)\n","Epoch 3: [130/196]\tTime 0.228 (0.236)\tData 0.002 (0.008)\tLoss 0.0139 (0.0157)\tPrec@1 100.000 (99.585)\n","Epoch 3: [140/196]\tTime 0.226 (0.235)\tData 0.001 (0.008)\tLoss 0.0160 (0.0154)\tPrec@1 99.609 (99.598)\n","Epoch 3: [150/196]\tTime 0.227 (0.235)\tData 0.002 (0.007)\tLoss 0.0122 (0.0152)\tPrec@1 99.219 (99.594)\n","Epoch 3: [160/196]\tTime 0.227 (0.234)\tData 0.001 (0.007)\tLoss 0.0048 (0.0150)\tPrec@1 100.000 (99.597)\n","Epoch 3: [170/196]\tTime 0.227 (0.234)\tData 0.002 (0.007)\tLoss 0.0107 (0.0147)\tPrec@1 100.000 (99.607)\n","Epoch 3: [180/196]\tTime 0.228 (0.234)\tData 0.002 (0.006)\tLoss 0.0169 (0.0149)\tPrec@1 99.609 (99.599)\n","Epoch 3: [190/196]\tTime 0.228 (0.233)\tData 0.001 (0.006)\tLoss 0.0086 (0.0149)\tPrec@1 100.000 (99.599)\n","Test: [10/100]\tTime 0.043 (0.101)\tLoss 0.3084 (0.2364)\tPrec@1 92.000 (93.300)\n","Test: [20/100]\tTime 0.045 (0.073)\tLoss 0.3933 (0.2344)\tPrec@1 90.000 (93.250)\n","Test: [30/100]\tTime 0.044 (0.064)\tLoss 0.1545 (0.2376)\tPrec@1 95.000 (93.100)\n","Test: [40/100]\tTime 0.045 (0.059)\tLoss 0.2391 (0.2379)\tPrec@1 95.000 (93.200)\n","Test: [50/100]\tTime 0.044 (0.056)\tLoss 0.4166 (0.2505)\tPrec@1 88.000 (92.920)\n","Test: [60/100]\tTime 0.044 (0.055)\tLoss 0.1687 (0.2460)\tPrec@1 96.000 (93.167)\n","Test: [70/100]\tTime 0.044 (0.053)\tLoss 0.2842 (0.2368)\tPrec@1 93.000 (93.443)\n","Test: [80/100]\tTime 0.044 (0.052)\tLoss 0.1495 (0.2393)\tPrec@1 96.000 (93.450)\n","Test: [90/100]\tTime 0.043 (0.051)\tLoss 0.1782 (0.2391)\tPrec@1 95.000 (93.389)\n","Test: [100/100]\tTime 0.043 (0.050)\tLoss 0.0888 (0.2359)\tPrec@1 97.000 (93.550)\n"," * Prec@1 93.550\n","Epoch 4: [10/196]\tTime 0.227 (0.334)\tData 0.000 (0.091)\tLoss 0.0086 (0.0118)\tPrec@1 99.609 (99.570)\n","Epoch 4: [20/196]\tTime 0.228 (0.281)\tData 0.001 (0.046)\tLoss 0.0039 (0.0116)\tPrec@1 100.000 (99.570)\n","Epoch 4: [30/196]\tTime 0.229 (0.263)\tData 0.002 (0.031)\tLoss 0.0122 (0.0124)\tPrec@1 99.609 (99.570)\n","Epoch 4: [40/196]\tTime 0.230 (0.254)\tData 0.002 (0.024)\tLoss 0.0050 (0.0131)\tPrec@1 100.000 (99.580)\n","Epoch 4: [50/196]\tTime 0.228 (0.249)\tData 0.001 (0.019)\tLoss 0.0146 (0.0127)\tPrec@1 100.000 (99.625)\n","Epoch 4: [60/196]\tTime 0.227 (0.245)\tData 0.002 (0.016)\tLoss 0.0134 (0.0129)\tPrec@1 99.219 (99.622)\n","Epoch 4: [70/196]\tTime 0.227 (0.243)\tData 0.001 (0.014)\tLoss 0.0102 (0.0130)\tPrec@1 100.000 (99.637)\n","Epoch 4: [80/196]\tTime 0.227 (0.241)\tData 0.001 (0.013)\tLoss 0.0084 (0.0122)\tPrec@1 100.000 (99.678)\n","Epoch 4: [90/196]\tTime 0.227 (0.239)\tData 0.002 (0.011)\tLoss 0.0073 (0.0126)\tPrec@1 100.000 (99.666)\n","Epoch 4: [100/196]\tTime 0.226 (0.238)\tData 0.002 (0.010)\tLoss 0.0141 (0.0123)\tPrec@1 99.609 (99.680)\n","Epoch 4: [110/196]\tTime 0.227 (0.237)\tData 0.001 (0.010)\tLoss 0.0230 (0.0126)\tPrec@1 98.828 (99.670)\n","Epoch 4: [120/196]\tTime 0.227 (0.236)\tData 0.001 (0.009)\tLoss 0.0139 (0.0127)\tPrec@1 99.609 (99.671)\n","Epoch 4: [130/196]\tTime 0.227 (0.236)\tData 0.002 (0.008)\tLoss 0.0109 (0.0127)\tPrec@1 99.609 (99.669)\n","Epoch 4: [140/196]\tTime 0.228 (0.235)\tData 0.001 (0.008)\tLoss 0.0102 (0.0125)\tPrec@1 100.000 (99.679)\n","Epoch 4: [150/196]\tTime 0.229 (0.235)\tData 0.001 (0.008)\tLoss 0.0219 (0.0125)\tPrec@1 99.219 (99.669)\n","Epoch 4: [160/196]\tTime 0.228 (0.234)\tData 0.001 (0.007)\tLoss 0.0190 (0.0126)\tPrec@1 99.609 (99.668)\n","Epoch 4: [170/196]\tTime 0.226 (0.234)\tData 0.002 (0.007)\tLoss 0.0369 (0.0127)\tPrec@1 99.219 (99.669)\n","Epoch 4: [180/196]\tTime 0.229 (0.233)\tData 0.002 (0.007)\tLoss 0.0110 (0.0126)\tPrec@1 100.000 (99.679)\n","Epoch 4: [190/196]\tTime 0.227 (0.233)\tData 0.002 (0.006)\tLoss 0.0121 (0.0125)\tPrec@1 100.000 (99.683)\n","Test: [10/100]\tTime 0.047 (0.101)\tLoss 0.3289 (0.2397)\tPrec@1 90.000 (93.700)\n","Test: [20/100]\tTime 0.047 (0.073)\tLoss 0.4172 (0.2520)\tPrec@1 90.000 (93.300)\n","Test: [30/100]\tTime 0.044 (0.064)\tLoss 0.1440 (0.2567)\tPrec@1 95.000 (93.433)\n","Test: [40/100]\tTime 0.044 (0.059)\tLoss 0.2607 (0.2538)\tPrec@1 95.000 (93.500)\n","Test: [50/100]\tTime 0.044 (0.056)\tLoss 0.4340 (0.2621)\tPrec@1 89.000 (93.200)\n","Test: [60/100]\tTime 0.044 (0.054)\tLoss 0.1771 (0.2545)\tPrec@1 95.000 (93.350)\n","Test: [70/100]\tTime 0.046 (0.053)\tLoss 0.2691 (0.2464)\tPrec@1 93.000 (93.529)\n","Test: [80/100]\tTime 0.044 (0.052)\tLoss 0.1921 (0.2484)\tPrec@1 94.000 (93.513)\n","Test: [90/100]\tTime 0.043 (0.051)\tLoss 0.2239 (0.2471)\tPrec@1 95.000 (93.500)\n","Test: [100/100]\tTime 0.042 (0.050)\tLoss 0.0959 (0.2405)\tPrec@1 96.000 (93.660)\n"," * Prec@1 93.660\n","==> Fine-tuned model accuracy\n","Test: [10/100]\tTime 0.043 (0.102)\tLoss 0.3289 (0.2397)\tPrec@1 90.000 (93.700)\n","Test: [20/100]\tTime 0.044 (0.074)\tLoss 0.4172 (0.2520)\tPrec@1 90.000 (93.300)\n","Test: [30/100]\tTime 0.044 (0.064)\tLoss 0.1440 (0.2567)\tPrec@1 95.000 (93.433)\n","Test: [40/100]\tTime 0.057 (0.060)\tLoss 0.2607 (0.2538)\tPrec@1 95.000 (93.500)\n","Test: [50/100]\tTime 0.045 (0.057)\tLoss 0.4340 (0.2621)\tPrec@1 89.000 (93.200)\n","Test: [60/100]\tTime 0.045 (0.055)\tLoss 0.1771 (0.2545)\tPrec@1 95.000 (93.350)\n","Test: [70/100]\tTime 0.045 (0.054)\tLoss 0.2691 (0.2464)\tPrec@1 93.000 (93.529)\n","Test: [80/100]\tTime 0.045 (0.053)\tLoss 0.1921 (0.2484)\tPrec@1 94.000 (93.513)\n","Test: [90/100]\tTime 0.043 (0.052)\tLoss 0.2239 (0.2471)\tPrec@1 95.000 (93.500)\n","Test: [100/100]\tTime 0.043 (0.051)\tLoss 0.0959 (0.2405)\tPrec@1 96.000 (93.660)\n"," * Prec@1 93.660\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["93.66"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"SNOhbmiSTmBs","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}