{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab_day1_classification_answer.ipynb","provenance":[{"file_id":"1vNHxfKObKTptZ6XeXd2ebLOmKoTmyeH6","timestamp":1593410879531}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"0Z8ckzgFHCcg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593398556670,"user_tz":-540,"elapsed":720,"user":{"displayName":"jaeseong lee","photoUrl":"","userId":"09106781948684028169"}},"outputId":"35c2a299-ee04-4fd3-9a25-0dca4b4aceec"},"source":["%tensorflow_version 1.x"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"g7Ye4sF6ZDux","colab_type":"text"},"source":["1. tf.keras.datasets API를 이용하여 MNIST dataset을 load해보자. "]},{"cell_type":"code","metadata":{"id":"cRukSZTCY-fF","colab_type":"code","colab":{}},"source":["nb_classes = 10\n","import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.datasets.mnist import load_data\n","(X_train, y_train), (X_test, y_test) = load_data()\n","print(X_train.shape, y_train.shape)\n","print(X_test.shape, y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WwQuTivbZcRC","colab_type":"text"},"source":["2. Softmax classifier를 구현해보고 train/test 해보자. learning rate 0.1, epoch = 15\n","3. MNIST dataset에서 image 한 개를 불러내어, softmax classifier로 prediction을 진행해보자."]},{"cell_type":"code","metadata":{"id":"JUNA7KlUZjLV","colab_type":"code","colab":{}},"source":["#Implement softmax classifier here\n","x = tf.placeholder(tf.float32, shape=[None, 28, 28])\n","y = tf.placeholder(tf.int32, shape=[None,])\n","\n","X = tf.reshape(x, [-1, 28 * 28])\n","Y_one_hot = tf.one_hot(y, 10)  # one hot\n","print(\"reshape one_hot:\", Y_one_hot)\n","Y_one_hot = tf.reshape(Y_one_hot, [-1, 10])\n","print(\"reshape one_hot:\", Y_one_hot)\n","\n","W = tf.Variable(tf.random_normal([28 * 28 * 1, 10]))\n","b = tf.Variable(tf.random_normal([10]))\n","\n","logits = tf.matmul(X, W) + b\n","hypo = tf.nn.softmax(logits)\n","\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_one_hot, logits=logits))\n","train = tf.train.GradientDescentOptimizer(1e-1).minimize(cost)\n","\n","prediction = tf.argmax(hypo, 1)\n","correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8sL4zMOrZ1zy","colab_type":"code","colab":{}},"source":["import random\n","import matplotlib.pyplot as plt\n","def train_and_test():\n","  batch_size = 100\n","  train_steps_in_epoch = X_train.shape[0] // batch_size\n","  log_interval = 100\n","  max_epoch = 25\n","\n","  with tf.Session() as sess:\n","      #Implement train & test logic here\n","      sess.run(tf.global_variables_initializer())\n","      for epoch in range(max_epoch):\n","          for i in range(train_steps_in_epoch):\n","              start = i*batch_size\n","              end = (i+1)*batch_size\n","              batch_x, batch_y = X_train[start:end], y_train[start:end]\n","              _, cost_val = sess.run([train, cost], feed_dict={x: batch_x, y: batch_y})\n","              if i % log_interval == 0:\n","                  print(\"steps: %d, loss: %f\" % (i, cost_val))\n","\n","          test_accuracy = sess.run(accuracy, feed_dict={x: X_test, y: y_test})\n","          print(\"%d epoch's Test accuracy: %f\" % (epoch+1, test_accuracy))\n","      \n","      #implement random image test\n","      r = random.randint(0, len(X_test) - 1)\n","      print(\"Label: \", y_test[r])\n","      print(X_test[r:r+1].shape)\n","      print(\n","          \"Prediction: \",\n","          sess.run(tf.argmax(hypo, 1), feed_dict={x: X_test[r:r+1]}),\n","      )\n","\n","      plt.imshow(\n","          X_test[r:r+1].reshape(28, 28),\n","          cmap=\"Greys\",\n","          interpolation=\"nearest\",\n","      )\n","      plt.show()\n","# train_and_test()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_sstLvQ6b8Po","colab_type":"text"},"source":["4. 수업시간에 배운 min_max_scaler를 이용해 주어진 데이터를 normalize 한 다음에 train / test해보자. 제약조건은 동일하다. 3.과 비교해보자."]},{"cell_type":"code","metadata":{"id":"Z9nZYiiEcGKt","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.datasets.mnist import load_data\n","(X_train, y_train), (X_test, y_test) = load_data()\n","print(X_train.shape, y_train.shape)\n","\n","#Implement min_max_scaler here\n","train_max = X_train.max()\n","train_min = X_train.min()\n","print(train_max, train_min)\n","\n","def min_max_scaler(data, data_min, data_max):\n","    numerator = data - data_min\n","    denominator = data_max - data_min\n","    return numerator / (denominator + 1e-7)\n","\n","X_train = min_max_scaler(X_train, train_min, train_max)\n","X_test = min_max_scaler(X_test, train_min, train_max)\n","\n","train_and_test()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbNkeXYn8qTr","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.datasets.mnist import load_data\n","(X_train, y_train), (X_test, y_test) = load_data()\n","print(X_train.shape, y_train.shape)\n","\n","train_mean = X_train.mean()\n","train_std = X_train.std()\n","print(train_mean, train_std)\n","\n","def normalize(data, mean, std):\n","    return (data - mean) / std\n","\n","X_train = normalize(X_train, train_mean, train_std)\n","X_test = normalize(X_test, train_mean, train_std)\n","\n","print(X_train.mean(), X_train.std())\n","\n","train_and_test()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J2ofsCZleQ2X","colab_type":"text"},"source":["5. L2 regularization을 구현해서 적용해보자"]},{"cell_type":"code","metadata":{"id":"PLqrfJ3KHFia","colab_type":"code","colab":{}},"source":["#Implement softmax classifier here\n","x = tf.placeholder(tf.float32, shape=[None, 28, 28])\n","y = tf.placeholder(tf.int32, shape=[None,])\n","\n","X = tf.reshape(x, [-1, 28 * 28])\n","Y_one_hot = tf.one_hot(y, 10)  # one hot\n","print(\"reshape one_hot:\", Y_one_hot)\n","Y_one_hot = tf.reshape(Y_one_hot, [-1, 10])\n","print(\"reshape one_hot:\", Y_one_hot)\n","\n","W = tf.Variable(tf.random_normal([28 * 28 * 1, 10]))\n","b = tf.Variable(tf.random_normal([10]))\n","\n","logits = tf.matmul(X, W) + b\n","hypo = tf.nn.softmax(logits)\n","\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_one_hot, logits=logits))\n","beta = 1e-5\n","# cost = cost + beta * tf.reduce_sum(W * W) / 2\n","cost = cost + beta * tf.nn.l2_loss(W)\n","\n","train = tf.train.GradientDescentOptimizer(1e-1).minimize(cost)\n","\n","prediction = tf.argmax(hypo, 1)\n","correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","import random\n","import matplotlib.pyplot as plt\n","def train_and_test():\n","  batch_size = 100\n","  train_steps_in_epoch = X_train.shape[0] // batch_size\n","  log_interval = 100\n","  max_epoch = 25\n","\n","  with tf.Session() as sess:\n","      #Implement train & test logic here\n","      sess.run(tf.global_variables_initializer())\n","      for epoch in range(max_epoch):\n","          for i in range(train_steps_in_epoch):\n","              start = i*batch_size\n","              end = (i+1)*batch_size\n","              batch_x, batch_y = X_train[start:end], y_train[start:end]\n","              _, cost_val = sess.run([train, cost], feed_dict={x: batch_x, y: batch_y})\n","              if i % log_interval == 0:\n","                  print(\"steps: %d, loss: %f\" % (i, cost_val))\n","\n","          test_accuracy = sess.run(accuracy, feed_dict={x: X_test, y: y_test})\n","          print(\"%d epoch's Test accuracy: %f\" % (epoch+1, test_accuracy))\n","      \n","      #implement random image test\n","      r = random.randint(0, len(X_test) - 1)\n","      print(\"Label: \", y_test[r])\n","      print(X_test[r:r+1].shape)\n","      print(\n","          \"Prediction: \",\n","          sess.run(tf.argmax(hypo, 1), feed_dict={x: X_test[r:r+1]}),\n","      )\n","\n","      plt.imshow(\n","          X_test[r:r+1].reshape(28, 28),\n","          cmap=\"Greys\",\n","          interpolation=\"nearest\",\n","      )\n","      plt.show()\n","train_and_test()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BYQ0LJp_v1vI","colab_type":"text"},"source":["6. MNIST dataset 대신 CIFAR10 dataset을 이용하여,\n","softmax classifier를 작성해보자. 제약조건은 이전과 동일하다.\n","image 한 개를 불러내어, softmax classifier로 prediction을 진행해보자.\n"]},{"cell_type":"code","metadata":{"id":"TEO6t2pLHJDb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593399337740,"user_tz":-540,"elapsed":57488,"user":{"displayName":"jaeseong lee","photoUrl":"","userId":"09106781948684028169"}},"outputId":"dd8f765d-95d8-46f7-ada3-5fd090adeabe"},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow.keras.datasets.cifar10 import load_data\n","(X_train, y_train), (X_test, y_test) = load_data()\n","print(X_train.shape, y_train.shape)\n","\n","train_mean = X_train.mean(axis=(0,1,2))\n","train_std = X_train.std(axis=(0,1,2))\n","print(train_mean, train_std)\n","\n","def normalize(data, mean, std):\n","    return (data - mean) / std\n","\n","orig_X_test = X_test\n","X_train = normalize(X_train, train_mean, train_std)\n","X_test = normalize(X_test, train_mean, train_std)\n","\n","print(X_train.min(), X_train.max(), X_train.mean(), X_train.std())\n","\n","#Implement softmax classifier here\n","x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n","y = tf.placeholder(tf.int32, shape=[None, 1])\n","\n","X = tf.reshape(x, [-1, 32 * 32 * 3])\n","Y_one_hot = tf.one_hot(y, 10)  # one hot\n","print(\"reshape one_hot:\", Y_one_hot)\n","Y_one_hot = tf.reshape(Y_one_hot, [-1, 10])\n","print(\"reshape one_hot:\", Y_one_hot)\n","\n","W = tf.Variable(tf.random_normal([32 * 32 * 3, 10]))\n","b = tf.Variable(tf.random_normal([10]))\n","\n","logits = tf.matmul(X, W) + b\n","hypo = tf.nn.softmax(logits)\n","\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_one_hot, logits=logits))\n","beta = 1e-5\n","# cost = cost + beta * tf.reduce_sum(W * W) / 2\n","cost = cost + beta * tf.nn.l2_loss(W)\n","\n","train = tf.train.GradientDescentOptimizer(1e-1).minimize(cost)\n","\n","prediction = tf.argmax(hypo, 1)\n","correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","import random\n","import matplotlib.pyplot as plt\n","batch_size = 100\n","train_steps_in_epoch = X_train.shape[0] // batch_size\n","log_interval = 100\n","max_epoch = 25\n","\n","with tf.Session() as sess:\n","    #Implement train & test logic here\n","    sess.run(tf.global_variables_initializer())\n","    for epoch in range(max_epoch):\n","        for i in range(train_steps_in_epoch):\n","            start = i*batch_size\n","            end = (i+1)*batch_size\n","            batch_x, batch_y = X_train[start:end], y_train[start:end]\n","            _, cost_val = sess.run([train, cost], feed_dict={x: batch_x, y: batch_y})\n","            if i % log_interval == 0:\n","                print(\"steps: %d, loss: %f\" % (i, cost_val))\n","\n","        test_accuracy = sess.run(accuracy, feed_dict={x: X_test, y: y_test})\n","        print(\"%d epoch's Test accuracy: %f\" % (epoch+1, test_accuracy))\n","    \n","    #implement random image test\n","    r = random.randint(0, len(orig_X_test) - 1)\n","    print(\"Label: \", y_test[r])\n","    print(orig_X_test[r:r+1].shape)\n","    print(\n","        \"Prediction: \",\n","        sess.run(tf.argmax(hypo, 1), feed_dict={x: orig_X_test[r:r+1]}),\n","    )\n","\n","    plt.imshow(\n","        orig_X_test[r:r+1].reshape(32, 32, 3),\n","        interpolation=\"nearest\",\n","    )\n","    plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(50000, 32, 32, 3) (50000, 1)\n","[125.30691805 122.95039414 113.86538318] [62.99321928 62.08870764 66.70489964]\n","-1.98921279913639 2.1267894095169213 5.2147915615326686e-17 0.9999999999999961\n","reshape one_hot: Tensor(\"one_hot_5:0\", shape=(?, 1, 10), dtype=float32)\n","reshape one_hot: Tensor(\"Reshape_11:0\", shape=(?, 10), dtype=float32)\n","steps: 0, loss: 71.200600\n","steps: 100, loss: 27.072315\n","steps: 200, loss: 26.672487\n","steps: 300, loss: 21.752735\n","steps: 400, loss: 16.104349\n","1 epoch's Test accuracy: 0.254800\n","steps: 0, loss: 17.027208\n","steps: 100, loss: 14.554087\n","steps: 200, loss: 19.363270\n","steps: 300, loss: 15.225926\n","steps: 400, loss: 12.478217\n","2 epoch's Test accuracy: 0.257500\n","steps: 0, loss: 12.642439\n","steps: 100, loss: 11.258831\n","steps: 200, loss: 15.839004\n","steps: 300, loss: 12.725488\n","steps: 400, loss: 10.336375\n","3 epoch's Test accuracy: 0.248800\n","steps: 0, loss: 10.710883\n","steps: 100, loss: 9.656334\n","steps: 200, loss: 12.697236\n","steps: 300, loss: 11.320501\n","steps: 400, loss: 8.900318\n","4 epoch's Test accuracy: 0.251400\n","steps: 0, loss: 9.595508\n","steps: 100, loss: 8.704006\n","steps: 200, loss: 11.803725\n","steps: 300, loss: 9.749205\n","steps: 400, loss: 8.512945\n","5 epoch's Test accuracy: 0.250500\n","steps: 0, loss: 9.436330\n","steps: 100, loss: 8.092360\n","steps: 200, loss: 10.464236\n","steps: 300, loss: 9.323960\n","steps: 400, loss: 7.972741\n","6 epoch's Test accuracy: 0.251600\n","steps: 0, loss: 8.557078\n","steps: 100, loss: 7.865418\n","steps: 200, loss: 10.569662\n","steps: 300, loss: 8.297640\n","steps: 400, loss: 7.286713\n","7 epoch's Test accuracy: 0.258700\n","steps: 0, loss: 8.115371\n","steps: 100, loss: 6.967049\n","steps: 200, loss: 9.836479\n","steps: 300, loss: 8.593894\n","steps: 400, loss: 6.950413\n","8 epoch's Test accuracy: 0.257500\n","steps: 0, loss: 7.555784\n","steps: 100, loss: 7.156081\n","steps: 200, loss: 9.149183\n","steps: 300, loss: 8.126650\n","steps: 400, loss: 6.643037\n","9 epoch's Test accuracy: 0.258400\n","steps: 0, loss: 7.074720\n","steps: 100, loss: 6.902339\n","steps: 200, loss: 9.546119\n","steps: 300, loss: 8.524240\n","steps: 400, loss: 6.746160\n","10 epoch's Test accuracy: 0.271200\n","steps: 0, loss: 6.905066\n","steps: 100, loss: 6.979443\n","steps: 200, loss: 9.599119\n","steps: 300, loss: 7.403430\n","steps: 400, loss: 6.511368\n","11 epoch's Test accuracy: 0.266300\n","steps: 0, loss: 6.646670\n","steps: 100, loss: 6.703462\n","steps: 200, loss: 9.355385\n","steps: 300, loss: 7.646362\n","steps: 400, loss: 6.403248\n","12 epoch's Test accuracy: 0.271100\n","steps: 0, loss: 6.624876\n","steps: 100, loss: 6.447014\n","steps: 200, loss: 9.373354\n","steps: 300, loss: 6.780505\n","steps: 400, loss: 6.122167\n","13 epoch's Test accuracy: 0.267600\n","steps: 0, loss: 6.568343\n","steps: 100, loss: 6.304946\n","steps: 200, loss: 9.141912\n","steps: 300, loss: 6.610027\n","steps: 400, loss: 6.051393\n","14 epoch's Test accuracy: 0.267600\n","steps: 0, loss: 7.180365\n","steps: 100, loss: 6.622630\n","steps: 200, loss: 8.941683\n","steps: 300, loss: 6.409406\n","steps: 400, loss: 6.224933\n","15 epoch's Test accuracy: 0.263100\n","steps: 0, loss: 6.346430\n","steps: 100, loss: 6.682022\n","steps: 200, loss: 8.325223\n","steps: 300, loss: 6.440143\n","steps: 400, loss: 6.064296\n","16 epoch's Test accuracy: 0.276800\n","steps: 0, loss: 5.942019\n","steps: 100, loss: 6.507746\n","steps: 200, loss: 9.441919\n","steps: 300, loss: 7.059542\n","steps: 400, loss: 5.924169\n","17 epoch's Test accuracy: 0.280600\n","steps: 0, loss: 5.759117\n","steps: 100, loss: 6.492477\n","steps: 200, loss: 8.391276\n","steps: 300, loss: 7.340713\n","steps: 400, loss: 5.887452\n","18 epoch's Test accuracy: 0.276900\n","steps: 0, loss: 6.696913\n","steps: 100, loss: 5.952298\n","steps: 200, loss: 8.584744\n","steps: 300, loss: 6.940073\n","steps: 400, loss: 6.097844\n","19 epoch's Test accuracy: 0.280200\n","steps: 0, loss: 6.140276\n","steps: 100, loss: 6.115594\n","steps: 200, loss: 8.403725\n","steps: 300, loss: 5.606453\n","steps: 400, loss: 5.608481\n","20 epoch's Test accuracy: 0.294700\n","steps: 0, loss: 5.058628\n","steps: 100, loss: 6.459347\n","steps: 200, loss: 8.883951\n","steps: 300, loss: 6.876256\n","steps: 400, loss: 5.688678\n","21 epoch's Test accuracy: 0.297900\n","steps: 0, loss: 4.892587\n","steps: 100, loss: 6.172210\n","steps: 200, loss: 8.844005\n","steps: 300, loss: 6.552703\n","steps: 400, loss: 5.648574\n","22 epoch's Test accuracy: 0.292900\n","steps: 0, loss: 4.944635\n","steps: 100, loss: 5.573938\n","steps: 200, loss: 8.599600\n","steps: 300, loss: 6.561938\n","steps: 400, loss: 5.345894\n","23 epoch's Test accuracy: 0.284900\n","steps: 0, loss: 4.887178\n","steps: 100, loss: 6.351955\n","steps: 200, loss: 8.078328\n","steps: 300, loss: 5.937403\n","steps: 400, loss: 5.932553\n","24 epoch's Test accuracy: 0.290900\n","steps: 0, loss: 5.009060\n","steps: 100, loss: 5.366638\n","steps: 200, loss: 7.777866\n","steps: 300, loss: 6.578894\n","steps: 400, loss: 5.454856\n","25 epoch's Test accuracy: 0.273000\n","Label:  [5]\n","(1, 32, 32, 3)\n","Prediction:  [1]\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"oW-xjfQLzRtq","colab_type":"text"},"source":["7. examples.tutorials.mnist 모듈을 사용하여 4.에서 작성한 코드를 간소화 해보자"]},{"cell_type":"code","metadata":{"id":"Daxu2M4rwLq0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":161},"executionInfo":{"status":"ok","timestamp":1592970549679,"user_tz":-540,"elapsed":1215,"user":{"displayName":"jaeseong lee","photoUrl":"","userId":"09106781948684028169"}},"outputId":"6c1c244d-6913-4589-b2b6-3d97a10e12de"},"source":["from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True, validation_size=0)\n","# reshape of X and one_hot of Y and min_max scale is already done here\n","print(mnist.train.images.shape, mnist.train.labels.shape)\n","print(mnist.test.images.shape, mnist.test.labels.shape)\n","print(mnist.train.images.min(), mnist.train.images.max())\n","print(mnist.train.num_examples)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Extracting MNIST_data/train-images-idx3-ubyte.gz\n","Extracting MNIST_data/train-labels-idx1-ubyte.gz\n","Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n","Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n","(60000, 784) (60000, 10)\n","(10000, 784) (10000, 10)\n","0.0 1.0\n","60000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XMPb6tvcz05C","colab_type":"code","colab":{}},"source":["#Implement softmax classifier here\n","X = tf.placeholder(tf.float32, shape=[None, 784])\n","Y = tf.placeholder(tf.int32, shape=[None, 10])\n","\n","W = tf.Variable(tf.random_normal([28 * 28 * 1, 10]))\n","b = tf.Variable(tf.random_normal([10]))\n","\n","logits = tf.matmul(X, W) + b\n","hypo = tf.nn.softmax(logits)\n","\n","cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n","beta = 1e-5\n","# cost = cost + beta * tf.reduce_sum(W * W) / 2\n","cost = cost + beta * tf.nn.l2_loss(W)\n","\n","train = tf.train.GradientDescentOptimizer(1e-1).minimize(cost)\n","\n","prediction = tf.argmax(hypo, 1)\n","correct_prediction = tf.equal(prediction, tf.argmax(Y, 1))\n","accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","\n","import random\n","import matplotlib.pyplot as plt\n","def train_and_test():\n","  batch_size = 100\n","  train_steps_in_epoch = mnist.train.num_examples // batch_size\n","  log_interval = 100\n","  max_epoch = 25\n","\n","  with tf.Session() as sess:\n","      # train & test\n","      sess.run(tf.global_variables_initializer())\n","      for epoch in range(max_epoch):\n","          for i in range(train_steps_in_epoch):\n","              batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n","              # start = i*batch_size\n","              # end = (i+1)*batch_size\n","              # batch_xs, batch_ys = X_train[start:end], y_train[start:end]\n","              _, cost_val = sess.run([train, cost], feed_dict={X: batch_x, Y: batch_y})\n","              if i % log_interval == 0:\n","                  print(\"steps: %d, loss: %f\" % (i, cost_val))\n","\n","          test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels})\n","          print(\"%d epoch's Test accuracy: %f\" % (epoch+1, test_accuracy))\n","train_and_test()"],"execution_count":null,"outputs":[]}]}