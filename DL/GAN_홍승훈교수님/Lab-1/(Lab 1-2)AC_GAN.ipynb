{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"(Lab 1-2)AC_GAN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOOl1NAzOIZESvLJDxgVTs9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4iySKmlBg97f","colab_type":"text"},"source":["# GANs for Image Generation tasks"]},{"cell_type":"markdown","metadata":{"id":"szfSTP2MkCZs","colab_type":"text"},"source":["## 2. Conditional GANs - AC-GAN"]},{"cell_type":"markdown","metadata":{"id":"dJjSXzlAmCOI","colab_type":"text"},"source":["### Prepare DataLoader for MNIST dataset"]},{"cell_type":"code","metadata":{"id":"i5Fuxt5dP7IZ","colab_type":"code","colab":{}},"source":["import torch\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import MNIST\n","from torchvision import transforms\n","\n","# fix manual seed.\n","torch.manual_seed(1234)\n","\n","# set batch size.\n","BATCH_SIZE = 256\n","\n","# prepare dataloader.\n","tf = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5], std=[0.5])\n","])\n","train_dataset = MNIST(root='./datasets', train=True, download=True, transform=tf)\n","loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sKfSVrjyJP36","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"yf6CYjavmK_y","colab_type":"text"},"source":["### Define GANs Models"]},{"cell_type":"markdown","metadata":{"id":"GFVC5C4wmQ5k","colab_type":"text"},"source":["#### Define Generator"]},{"cell_type":"code","metadata":{"id":"d1FepF4OmKVY","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","\n","        # ============================================================ #\n","        # TODO : Fill fully connected layers upconvolution layers\n","        # * Specificl details of model architectures are on the slides. \n","        # * Hint : Use following functions : \n","        #   nn.Linear(), nn.BatchNorm1d(), nn.ConvTranspose2d(), \n","        #   nn.BatchNorm2d(), nn.ReLU()\n","        # ============================================================ #\n","\n","        self.z_dim = 64\n","        self.hidden_dim = 256\n","        self.img_dim = 28 * 28\n","\n","        self.fc = nn.Sequential(\n","            # Fill here.   \n","        )\n","        \n","        self.upconv = nn.Sequential(\n","            # Fill here.   \n","        )\n","        \n","    def forward(self, x):\n","        # ============================================================ #\n","        # TODO : Complete forward function. \n","        # * Hint : Use self.fc and self.upconv defined above\n","        # ============================================================ #\n","\n","        # Fill here. \n","        \n","        return out\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ajYUrgp0mUt8","colab_type":"text"},"source":["#### Define Discriminator"]},{"cell_type":"code","metadata":{"id":"5upJT6CemOz6","colab_type":"code","colab":{}},"source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","\n","        # ============================================================ #\n","        # TODO : Fill convolution layers and fully connected layers.\n","        # * Specificl details of model architectures are on the slides. \n","        # * Hint : Use following functions : \n","        #   nn.Conv2d(), nn.LeaklyReLU(), nn.Linear(), nn.BatchNorm1d(),\n","        #   nn.Sigmoid()\n","        # ============================================================ #\n","        \n","        self.img_dim = 28 * 28\n","        self.hidden_dim = 256\n","        self.num_class = 10\n","\n","        self.conv = nn.Sequential(\n","            # Fill here.   \n","\n","        )\n","        self.fc = nn.Sequential(\n","            # Fill here.   \n","\n","        )\n","        self.fc_disc = nn.Sequential(\n","            # Fill here.   \n","\n","        )\n","        \n","        self.fc_cls = nn.Sequential(\n","            # Fill here.   \n","        )\n","\n","    def forward(self, x):\n","        # ============================================================ #\n","        # TODO : Complete forward function. \n","        # * Hint : Use self.fc and self.upconv defined above\n","        #    - out_disc : head for real/fake discrimination \n","        #    - out_cls : head for classification\n","        # ============================================================ #\n","\n","        # Fill here.   \n","\n","        return out_disc, out_cls\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z7yQUvj2rMLU","colab_type":"text"},"source":["#### Prepare GAN model and Optimizers"]},{"cell_type":"code","metadata":{"id":"Irabx2XtoRhY","colab_type":"code","colab":{}},"source":["# weight initialization function. \n","def weights_init(net):\n","    for m in net.modules():\n","        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","            m.weight.data.normal_(0, 0.02)\n","            if m.bias is not None:\n","                m.bias.data.zero_()\n","\n","# define GAN model.\n","G = Generator().cuda()\n","D = Discriminator().cuda()\n","\n","# weight initialization & set both modes to train mode.\n","G.apply(weights_init)\n","D.apply(weights_init)\n","\n","# define optimizer. Here we use Adam optimizer. \n","optimizer_G = torch.optim.Adam(G.parameters(), lr=2e-4, betas=(0.5,0.999))\n","optimizer_D = torch.optim.Adam(D.parameters(), lr=2e-4, betas=(0.5,0.999))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MhfKpgHmnQz_","colab_type":"text"},"source":["#### Start training GAN"]},{"cell_type":"code","metadata":{"id":"pJWTZUxxeQ2I","colab_type":"code","colab":{}},"source":["# install tensorboardx to use tensorboard.\n","%pip install tensorboardx\n","\n","from tensorboardX import SummaryWriter\n","from torchvision.utils import make_grid\n","\n","# Hyper-parameters. \n","# ====== You don't need to change here ===== #\n","EPOCHS = 50\n","Z_DIM = 64\n","NUM_CLASS = 10\n","# ========================================== #\n","\n","# logger for tensorboard.\n","logger = SummaryWriter()\n","\n","# Fixed latent variable z, label y for visualization. \n","FIXED_Z = torch.randn(size=(100,Z_DIM)).cuda()\n","FIXED_Y = torch.arange(10).repeat(10)\n","FIXED_Y = torch.zeros(size=(100,NUM_CLASS)).scatter_(1, FIXED_Y.unsqueeze(1), 1).cuda()\n","\n","# GT labels for calculating binary cross entropy loss. \n","real_label = torch.ones(size=(BATCH_SIZE,1)).cuda()\n","fake_label = torch.zeros(size=(BATCH_SIZE,1)).cuda()\n","\n","# criterion for binary cross entropy loss\n","BCE_criterion = torch.nn.BCELoss()\n","CE_criterion = torch.nn.CrossEntropyLoss()\n","\n","for epoch in range(EPOCHS):\n","    # Set both models to train modes.\n","    G.train()\n","    D.train()\n","\n","    # For logging in tensorboard\n","    loss_G_total, loss_D_total = 0., 0.\n","\n","    for batch_idx, (data, label) in enumerate(loader):\n","        data = data.cuda()\n","        label = label.cuda()\n","        \n","        # ============================================================ #\n","        # TODO : Fill the part for updating D&G.\n","        # First sample z and y. \n","        # z : (BATCH_SIZE, Z_DIM) size random latent variable\n","        # y : (BATCH_SIZE, NUM_CLASS) size random label\n","        # Then Calculate GAN loss (loss_D, loss_G)\n","        # * Don't forget, you should also consider classification loss!!!     \n","        # ============================================================ #\n","\n","        # ================= Update D ================== # \n","                       \n","        # Fill here. \n","        # First compute loss_D \n","        # Then update the network with loss_D using optimizer_D\n","\n","        # ================= Update G ================== # \n"," \n","        # Fill here. \n","        # First compute loss_G \n","        # Then update the network with loss_G using optimizer_G.\n","        # Note that we need additional auxiliary classification loss.\n","\n","        loss_D_total += loss_D.item()\n","        loss_G_total += loss_G.item()\n","        \n","        # print current states\n","        if batch_idx % 100  == 0:\n","            print('Epoch : {} || {}/{} || loss_G={:.3f} loss_D={:.3f}'.format(\n","                epoch, batch_idx, len(loader), loss_G.item(), loss_D.item()\n","            ))\n","\n","    loss_G_total /= len(loader)\n","    loss_D_total /= len(loader)\n","\n","    # ================= Genearte example samples ================== # \n","    fake_img = G(FIXED_Z, FIXED_Y)\n","    fake_img = fake_img.view(fake_img.shape[0], 1, 28, 28)\n","    fake_img = (fake_img + 1)*0.5\n","    fake_img = make_grid(fake_img, nrow=10)\n","\n","    \n","    # ============================================================ #\n","    # TODO : Logging on the tensorboard\n","    # * log loss_G_total, loss_D_total, and fake_img\n","    # * use logger.add_scalar() and logger.add_image() for logging\n","    # ============================================================ #\n","\n","    # Fill here\n","        \n","    # print current states\n","    print('Epoch : {} has done. AVG loss : loss_G={:.3f} loss_D={:.3f}'.format(\n","        epoch, loss_G_total, loss_D_total\n","    ))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EV838kqpQKBC","colab_type":"code","colab":{}},"source":["# Check Tensorboard.\n","%ls runs\n","%load_ext tensorboard\n","%tensorboard --logdir runs --port 9999"],"execution_count":null,"outputs":[]}]}