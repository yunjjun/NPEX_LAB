{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Reference: https://github.com/jwyang/faster-rcnn.pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training code of faster-rcnn\n",
    " - Goal: understand overall training flow & check whether decreases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "from roi_data_layer.roidb import combined_roidb\n",
    "from roi_data_layer.roibatchLoader import roibatchLoader\n",
    "from model.utils.config import cfg, cfg_from_file, cfg_from_list, get_output_dir\n",
    "from model.utils.net_utils import weights_normal_init, save_net, load_net, \\\n",
    "      adjust_learning_rate, save_checkpoint, clip_gradient\n",
    "\n",
    "from model.faster_rcnn.vgg16 import vgg16\n",
    "from model.faster_rcnn.resnet import resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "dataset_name = 'pascal_voc'\n",
    "net = 'vgg16'\n",
    "start_epoch = 1\n",
    "max_epochs = 20\n",
    "disp_interval = 100\n",
    "checkpoint_interval = 10000\n",
    "save_dir = 'models'\n",
    "num_workers = 0\n",
    "cuda = True\n",
    "large_scale = False               \n",
    "mGPUs = False\n",
    "batch_size = 2\n",
    "class_agnostic = False\n",
    "\n",
    "# config optimization\n",
    "optimizer = \"sgd\"\n",
    "lr = 0.001\n",
    "lr_decay_step = 5\n",
    "lr_decay_gamma = 0.1\n",
    "\n",
    "# set training session\n",
    "session = 1\n",
    "\n",
    "# resume trained model\n",
    "resume = False\n",
    "checksession = 1\n",
    "checkepoch = 1\n",
    "checkpoint = 0\n",
    "\n",
    "# log and display\n",
    "use_tfboard = False\n",
    "\n",
    "imdb_name = \"voc_2007_trainval\"\n",
    "imdbval_name = \"voc_2007_test\"\n",
    "set_cfgs = ['ANCHOR_SCALES', '[8, 16, 32]', 'ANCHOR_RATIOS', '[0.5,1,2]', 'MAX_NUM_GT_BOXES', '20']\n",
    "cfg_file = \"cfgs/{}_ls.yml\".format(net) if large_scale else \"cfgs/{}.yml\".format(net)\n",
    "\n",
    "if cfg_file is not None:\n",
    "    cfg_from_file(cfg_file)\n",
    "if set_cfgs is not None:\n",
    "    cfg_from_list(set_cfgs)\n",
    "\n",
    "cfg.TRAIN.USE_FLIPPED = True\n",
    "cfg.USE_GPU_NMS = cuda    \n",
    "cfg.CUDA = True\n",
    "\n",
    "print('Using config:')\n",
    "pprint.pprint(cfg)\n",
    "np.random.seed(cfg.RNG_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Sampler class\n",
    " - argument of 'Dataloader' (sampler='')\n",
    " - define how to generate indices\n",
    " - if given, argument 'shuffle' should be None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sampler(Sampler):\n",
    "    def __init__(self, train_size, batch_size):\n",
    "        self.num_data = train_size\n",
    "        self.num_per_batch = int(train_size / batch_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.range = torch.arange(0,batch_size).view(1, batch_size).long()\n",
    "        self.leftover_flag = False\n",
    "        if train_size % batch_size:\n",
    "            self.leftover = torch.arange(self.num_per_batch*batch_size, train_size).long()\n",
    "            self.leftover_flag = True\n",
    "\n",
    "    def __iter__(self):\n",
    "        rand_num = torch.randperm(self.num_per_batch).view(-1,1) * self.batch_size\n",
    "        self.rand_num = rand_num.expand(self.num_per_batch, self.batch_size) + self.range\n",
    "\n",
    "        self.rand_num_view = self.rand_num.view(-1)\n",
    "\n",
    "        if self.leftover_flag:\n",
    "            self.rand_num_view = torch.cat((self.rand_num_view, self.leftover),0)\n",
    "\n",
    "        return iter(self.rand_num_view)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get train dataloader object\n",
    "<br>\n",
    " (1) Load data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "# -- Note: Use validation set and disable the flipped to enable faster loading.\n",
    "cfg.TRAIN.USE_FLIPPED = True\n",
    "cfg.USE_GPU_NMS = cuda\n",
    "imdb, roidb, ratio_list, ratio_index = combined_roidb(imdb_name)\n",
    "train_size = len(roidb)\n",
    "\n",
    "print('{:d} roidb entries'.format(len(roidb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) initialize dataset & sampler object <br>\n",
    "(3) get dataloader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_batch = sampler(train_size, batch_size)\n",
    "\n",
    "dataset = roibatchLoader(roidb, ratio_list, ratio_index, batch_size, \\\n",
    "                       imdb.num_classes, training=True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                        sampler=sampler_batch, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilize the input tensor holder here.\n",
    "im_data = torch.FloatTensor(1)\n",
    "im_info = torch.FloatTensor(1)\n",
    "num_boxes = torch.LongTensor(1)\n",
    "gt_boxes = torch.FloatTensor(1)\n",
    "\n",
    "print(num_boxes)\n",
    "\n",
    "# ship to cuda\n",
    "if cuda:\n",
    "    im_data = im_data.cuda()\n",
    "    im_info = im_info.cuda()\n",
    "    num_boxes = num_boxes.cuda()\n",
    "    gt_boxes = gt_boxes.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize object detection network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilize the network here.\n",
    "if net == 'vgg16':\n",
    "    fasterRCNN = vgg16(imdb.classes, pretrained=True, class_agnostic=class_agnostic)\n",
    "fasterRCNN.create_architecture()\n",
    "\n",
    "if cuda:\n",
    "    fasterRCNN.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get parameters of model\n",
    " - we can set different value of learning rate, weight_decay params, etc.\n",
    " - we can filter params whoose requires_grad is False (freezing network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for key, value in dict(fasterRCNN.named_parameters()).items():\n",
    "    if value.requires_grad:\n",
    "        if 'bias' in key:\n",
    "            params += [{'params':[value],'lr':lr*(cfg.TRAIN.DOUBLE_BIAS + 1), \\\n",
    "                        'weight_decay': cfg.TRAIN.BIAS_DECAY and cfg.TRAIN.WEIGHT_DECAY or 0}]\n",
    "        else:\n",
    "            params += [{'params':[value],'lr':lr, 'weight_decay': cfg.TRAIN.WEIGHT_DECAY}]\n",
    "optimizer = torch.optim.SGD(params, momentum=cfg.TRAIN.MOMENTUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main training iteration\n",
    " - get input data\n",
    " - forward\n",
    " - get loss\n",
    " - backward\n",
    " - save checkpoint (model weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_dir = save_dir + \"/\" + net + \"/\" + dataset_name\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "iters_per_epoch = int(train_size / batch_size)\n",
    "\n",
    "for epoch in range(start_epoch, max_epochs + 1):\n",
    "    # setting to train mode\n",
    "    fasterRCNN.train()\n",
    "    loss_temp = 0\n",
    "    start = time.time()\n",
    "\n",
    "    if epoch % (lr_decay_step + 1) == 0:\n",
    "        adjust_learning_rate(optimizer, lr_decay_gamma)\n",
    "        lr *= lr_decay_gamma\n",
    "\n",
    "    for step, data in enumerate(dataloader):\n",
    "        im_data.data.resize_(data[0].size()).copy_(data[0])\n",
    "        im_info.data.resize_(data[1].size()).copy_(data[1])\n",
    "        gt_boxes.data.resize_(data[2].size()).copy_(data[2])\n",
    "        num_boxes.data.resize_(data[3].size()).copy_(data[3])\n",
    "\n",
    "        # forward path\n",
    "        rois, cls_prob, bbox_pred, \\\n",
    "        rpn_loss_cls, rpn_loss_box, \\\n",
    "        RCNN_loss_cls, RCNN_loss_bbox, \\\n",
    "        rois_label = fasterRCNN(im_data, im_info, gt_boxes, num_boxes)\n",
    "        \n",
    "        # define total loss term\n",
    "        loss = rpn_loss_cls + rpn_loss_box \\\n",
    "           + RCNN_loss_cls + RCNN_loss_bbox\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_temp += loss.item()\n",
    "        if step % disp_interval == 0:\n",
    "            end = time.time()\n",
    "            if step > 0:\n",
    "                loss_temp /= (disp_interval + 1)\n",
    "\n",
    "            loss_rpn_cls = rpn_loss_cls.item()\n",
    "            loss_rpn_box = rpn_loss_box.item()\n",
    "            loss_rcnn_cls = RCNN_loss_cls.item()\n",
    "            loss_rcnn_box = RCNN_loss_bbox.item()\n",
    "            fg_cnt = torch.sum(rois_label.data.ne(0))\n",
    "            bg_cnt = rois_label.data.numel() - fg_cnt\n",
    "\n",
    "            print(\"[session %d][epoch %2d][iter %4d/%4d] loss: %.4f, lr: %.2e\" \\\n",
    "                                    % (session, epoch, step, iters_per_epoch, loss_temp, lr))\n",
    "            print(\"\\t\\t\\tfg/bg=(%d/%d), time cost: %f\" % (fg_cnt, bg_cnt, end-start))\n",
    "            print(\"\\t\\t\\trpn_cls: %.4f, rpn_box: %.4f, rcnn_cls: %.4f, rcnn_box %.4f\" \\\n",
    "                          % (loss_rpn_cls, loss_rpn_box, loss_rcnn_cls, loss_rcnn_box))\n",
    "\n",
    "            loss_temp = 0\n",
    "            start = time.time()\n",
    "\n",
    "    save_name = os.path.join(output_dir, 'faster_rcnn_{}_{}_{}.pth'.format(session, epoch, step))\n",
    "    save_checkpoint({\n",
    "        'session': session,\n",
    "        'epoch': epoch + 1,\n",
    "        'model': fasterRCNN.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'pooling_mode': cfg.POOLING_MODE,\n",
    "        'class_agnostic': class_agnostic,\n",
    "    }, save_name)\n",
    "    print('save model: {}'.format(save_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After checking loss decreasing, \n",
    " (0) Before running demo, please make sure whether images/ directory is empty. (remove '.ipynb_checkpoints/' or any other files/dirs)<br>\n",
    " (1) put your own images which contains at least one person into images/ directory <br>\n",
    " (2) type 'python demo.py --net vgg16 --checksession 1 --checkepoch 6 --checkpoint 10021 --cuda --load_dir models' <br>\n",
    " on root dir of project <br>\n",
    " (3) check the result of object detection at images/ directory\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
